{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import transformers as T\nfrom datasets import load_dataset\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.optim import AdamW\nfrom tqdm import tqdm\nfrom torchmetrics import SpearmanCorrCoef, Accuracy, F1Score","metadata":{"_uuid":"20ab6a09-f75e-47db-842e-73dd953cd346","_cell_guid":"6c156c0a-7a1b-4845-99c7-c169799201c3","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-11-26T02:12:57.565944Z","iopub.execute_input":"2024-11-26T02:12:57.566454Z","iopub.status.idle":"2024-11-26T02:12:57.571754Z","shell.execute_reply.started":"2024-11-26T02:12:57.566419Z","shell.execute_reply":"2024-11-26T02:12:57.570763Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"token_replacement = [\n    [\"：\" , \":\"],\n    [\"，\" , \",\"],\n    [\"“\" , \"\\\"\"],\n    [\"”\" , \"\\\"\"],\n    [\"？\" , \"?\"],\n    [\"……\" , \"...\"],\n    [\"！\" , \"!\"]\n]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-26T02:12:57.572880Z","iopub.execute_input":"2024-11-26T02:12:57.573183Z","iopub.status.idle":"2024-11-26T02:12:57.586026Z","shell.execute_reply.started":"2024-11-26T02:12:57.573155Z","shell.execute_reply":"2024-11-26T02:12:57.585415Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class SemevalDataset(Dataset):\n    def __init__(self, split=\"train\") -> None:\n        super().__init__()\n        assert split in [\"train\", \"validation\", \"test\"]\n        self.data = load_dataset(\n            \"sem_eval_2014_task_1\", split=split, cache_dir=\"./cache/\", trust_remote_code=True\n        ).to_list()\n\n    def __getitem__(self, index):\n        d = self.data[index]\n        # Token replacement\n        for k in [\"premise\", \"hypothesis\"]:\n            for tok in token_replacement:\n                d[k] = d[k].replace(tok[0], tok[1])\n        return d\n\n    def __len__(self):\n        return len(self.data)\n\ndata_sample = SemevalDataset(split=\"train\").data[:3]\nprint(f\"Dataset example: \\n{data_sample[0]} \\n{data_sample[1]} \\n{data_sample[2]}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-26T02:12:57.587597Z","iopub.execute_input":"2024-11-26T02:12:57.587875Z","iopub.status.idle":"2024-11-26T02:13:06.399130Z","shell.execute_reply.started":"2024-11-26T02:12:57.587849Z","shell.execute_reply":"2024-11-26T02:13:06.398191Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define the hyperparameters\nlr = 3e-5\nepochs = 10\ntrain_batch_size = 64\nvalidation_batch_size = 64\ntest_batch_size = 64","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-26T02:13:06.400328Z","iopub.execute_input":"2024-11-26T02:13:06.400713Z","iopub.status.idle":"2024-11-26T02:13:06.405290Z","shell.execute_reply.started":"2024-11-26T02:13:06.400675Z","shell.execute_reply":"2024-11-26T02:13:06.404428Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"tokenizer = T.BertTokenizer.from_pretrained(\"google-bert/bert-base-uncased\", cache_dir=\"./cache/\")\ndevice = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n# device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-26T02:13:06.407688Z","iopub.execute_input":"2024-11-26T02:13:06.408054Z","iopub.status.idle":"2024-11-26T02:13:07.546398Z","shell.execute_reply.started":"2024-11-26T02:13:06.408014Z","shell.execute_reply":"2024-11-26T02:13:07.545694Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# TODO1: Create batched data for DataLoader\n# `collate_fn` is a function that defines how the data batch should be packed.\n# This function will be called in the DataLoader to pack the data batch.\n\ndef collate_fn(batch):\n    # TODO1-1: Implement the collate_fn function\n    # Write your code here\n    # The input parameter is a data batch (tuple), and this function packs it into tensors.\n    # Use tokenizer to pack tokens and pack the data and its corresponding labels.\n    # Return the data batch and labels for each sub-task.\n    complete_text = [\n        f\"{example['premise']}[SEP]{example['hypothesis']}\"\n        for example in batch\n    ]\n    complete_text = tokenizer.batch_encode_plus(\n        complete_text,\n        padding=True,\n        truncation=True,\n        return_tensors=\"pt\",\n        add_special_tokens=False,\n    )\n    complete_text['labels_reg'] = torch.tensor([b['relatedness_score'] for b in batch])\n    complete_text['labels_cls'] = torch.tensor([b['entailment_judgment'] for b in batch])\n    \n    # Move the data to the device\n    complete_text = {k: complete_text[k].to(device) for k in complete_text}\n    \n    return complete_text\n\n# TODO1-2: Define your DataLoader\nds_train = SemevalDataset(\"train\")\nds_validation = SemevalDataset(\"validation\")\n\ndl_train = DataLoader(ds_train, batch_size=train_batch_size, shuffle=True, collate_fn=collate_fn)\ndl_validation = DataLoader(ds_validation, batch_size=validation_batch_size, shuffle=False, collate_fn=collate_fn)\n\nds_test = SemevalDataset(\"test\")\ndl_test = DataLoader(ds_test, batch_size=test_batch_size, shuffle=False, collate_fn=collate_fn)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-26T02:13:15.705009Z","iopub.execute_input":"2024-11-26T02:13:15.705841Z","iopub.status.idle":"2024-11-26T02:13:19.040483Z","shell.execute_reply.started":"2024-11-26T02:13:15.705802Z","shell.execute_reply":"2024-11-26T02:13:19.039550Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# RegModel","metadata":{}},{"cell_type":"code","source":"# TODO2: Construct your model\nclass RegModel(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        # Write your code here\n        # Define what modules you will use in the model\n        self.bert = T.BertModel.from_pretrained(\"google-bert/bert-base-uncased\", cache_dir=\"./cache/\")\n        self.regression_head = torch.nn.Sequential(\n            torch.nn.Linear(768, 384),\n            torch.nn.ReLU(),\n            torch.nn.Linear(384, 192),\n            torch.nn.ReLU(),\n            torch.nn.Linear(192, 1)\n        )\n        \n    def forward(self, **inputs):\n        # Write your code here\n        # Forward pass\n        # BERT\n        bert_output = self.bert(inputs['input_ids'], inputs['attention_mask'], inputs['token_type_ids'])\n        # [CLS] token hidden state\n        cls_token_output = bert_output.last_hidden_state[:, 0, :]\n        # Task-specific heads\n        reg_output = self.regression_head(cls_token_output)\n\n        return reg_output.squeeze(-1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-26T06:27:41.267390Z","iopub.execute_input":"2024-11-26T06:27:41.268194Z","iopub.status.idle":"2024-11-26T06:27:41.274814Z","shell.execute_reply.started":"2024-11-26T06:27:41.268153Z","shell.execute_reply":"2024-11-26T06:27:41.273607Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"# Use both GPUs\nmodel = RegModel()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-26T06:28:31.142541Z","iopub.execute_input":"2024-11-26T06:28:31.142890Z","iopub.status.idle":"2024-11-26T06:28:35.211868Z","shell.execute_reply.started":"2024-11-26T06:28:31.142859Z","shell.execute_reply":"2024-11-26T06:28:35.210957Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"db4a6ff284c74c8c9dd54e487f2d506b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a9918dddeea44c5f869afdf9eef22aef"}},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"# TODO3: Define your optimizer and loss function\n\n# TODO3-1: Define your Optimizer\n# optimizer = torch.optim.AdamW(model.parameters(), lr=lr)# Write your code here\noptimizer = torch.optim.AdamW([\n    {'params': model.bert.parameters(), 'lr': 3e-5},\n    {'params': model.regression_head.parameters(), 'lr': 3e-3},\n])\n\n# TODO3-2: Define your loss functions (you should have two)\n# Write your code here\ncriterion_reg = torch.nn.MSELoss()  # Regression loss\n\n# scoring functions\nspc = SpearmanCorrCoef().to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-26T06:28:35.262677Z","iopub.execute_input":"2024-11-26T06:28:35.262895Z","iopub.status.idle":"2024-11-26T06:28:35.864131Z","shell.execute_reply.started":"2024-11-26T06:28:35.262872Z","shell.execute_reply":"2024-11-26T06:28:35.863146Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: Metric `SpearmanCorrcoef` will save all targets and predictions in the buffer. For large datasets, this may lead to large memory footprint.\n  warnings.warn(*args, **kwargs)  # noqa: B028\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"# This is the sample code from Pytorch\nif torch.cuda.device_count() > 1:\n    print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n    model = torch.nn.DataParallel(model)\n    \nmodel = model.to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-26T06:28:41.169809Z","iopub.execute_input":"2024-11-26T06:28:41.170691Z","iopub.status.idle":"2024-11-26T06:28:41.335509Z","shell.execute_reply.started":"2024-11-26T06:28:41.170650Z","shell.execute_reply":"2024-11-26T06:28:41.334650Z"}},"outputs":[{"name":"stdout","text":"Let's use 2 GPUs!\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"%mkdir ./saved_models","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-26T06:28:43.008575Z","iopub.execute_input":"2024-11-26T06:28:43.008928Z","iopub.status.idle":"2024-11-26T06:28:44.097876Z","shell.execute_reply.started":"2024-11-26T06:28:43.008898Z","shell.execute_reply":"2024-11-26T06:28:44.096536Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"for ep in range(epochs):\n    pbar = tqdm(dl_train)\n    pbar.set_description(f\"Training epoch [{ep+1}/{epochs}]\")\n    model.train()\n    # TODO4: Write the training loop\n    # Write your code here\n    for inputs in pbar:\n        # train your model\n        # clear gradient\n        optimizer.zero_grad()\n        # forward pass\n        outputs_reg = model(**inputs)\n        # compute loss\n        loss_reg = criterion_reg(outputs_reg, inputs['labels_reg'])\n        # back-propagation\n        loss = loss_reg\n        loss.backward()\n        # model optimization\n        optimizer.step()\n        # update progress bar\n        pbar.set_postfix(loss=loss.item())\n\n    pbar = tqdm(dl_validation)\n    pbar.set_description(f\"Validation epoch [{ep+1}/{epochs}]\")\n    model.eval()\n    # TODO5: Write the evaluation loop\n    # Write your code here\n    for inputs in pbar:\n        # Evaluate your model\n        outputs_reg = None\n        with torch.no_grad():\n            outputs_reg = model(**inputs)\n        # Output all the evaluation scores (SpearmanCorrCoef, Accuracy, F1Score)\n        pred_reg = outputs_reg\n        spc.update(pred_reg, inputs['labels_reg'])\n\n    # Print the evaluation scores\n    print(f'Spearman CorrCoef: {spc.compute()}')\n    # Reset the evaluation metrics\n    spc.reset()\n    # Save the model\n    torch.save(model, f'./saved_models/ep{ep}.ckpt')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-26T06:30:20.509534Z","iopub.execute_input":"2024-11-26T06:30:20.510467Z","iopub.status.idle":"2024-11-26T06:35:03.558795Z","shell.execute_reply.started":"2024-11-26T06:30:20.510425Z","shell.execute_reply":"2024-11-26T06:35:03.557773Z"}},"outputs":[{"name":"stderr","text":"Training epoch [1/10]:   0%|          | 0/71 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\nTraining epoch [1/10]: 100%|██████████| 71/71 [00:26<00:00,  2.71it/s, loss=0.335]\nValidation epoch [1/10]: 100%|██████████| 8/8 [00:00<00:00, 10.11it/s]\n","output_type":"stream"},{"name":"stdout","text":"Spearman CorrCoef: 0.7854442596435547\n","output_type":"stream"},{"name":"stderr","text":"Training epoch [2/10]: 100%|██████████| 71/71 [00:24<00:00,  2.85it/s, loss=0.304]\nValidation epoch [2/10]: 100%|██████████| 8/8 [00:00<00:00, 10.06it/s]\n","output_type":"stream"},{"name":"stdout","text":"Spearman CorrCoef: 0.8087268471717834\n","output_type":"stream"},{"name":"stderr","text":"Training epoch [3/10]: 100%|██████████| 71/71 [00:25<00:00,  2.74it/s, loss=0.332]\nValidation epoch [3/10]: 100%|██████████| 8/8 [00:00<00:00,  9.46it/s]\n","output_type":"stream"},{"name":"stdout","text":"Spearman CorrCoef: 0.8221060037612915\n","output_type":"stream"},{"name":"stderr","text":"Training epoch [4/10]: 100%|██████████| 71/71 [00:26<00:00,  2.70it/s, loss=0.236]\nValidation epoch [4/10]: 100%|██████████| 8/8 [00:01<00:00,  7.84it/s]\n","output_type":"stream"},{"name":"stdout","text":"Spearman CorrCoef: 0.8258858323097229\n","output_type":"stream"},{"name":"stderr","text":"Training epoch [5/10]: 100%|██████████| 71/71 [00:27<00:00,  2.59it/s, loss=0.127] \nValidation epoch [5/10]: 100%|██████████| 8/8 [00:00<00:00,  8.95it/s]\n","output_type":"stream"},{"name":"stdout","text":"Spearman CorrCoef: 0.8315981030464172\n","output_type":"stream"},{"name":"stderr","text":"Training epoch [6/10]: 100%|██████████| 71/71 [00:27<00:00,  2.57it/s, loss=0.137] \nValidation epoch [6/10]: 100%|██████████| 8/8 [00:00<00:00,  9.28it/s]\n","output_type":"stream"},{"name":"stdout","text":"Spearman CorrCoef: 0.8240798115730286\n","output_type":"stream"},{"name":"stderr","text":"Training epoch [7/10]: 100%|██████████| 71/71 [00:27<00:00,  2.63it/s, loss=0.12]  \nValidation epoch [7/10]: 100%|██████████| 8/8 [00:00<00:00,  9.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"Spearman CorrCoef: 0.8321607708930969\n","output_type":"stream"},{"name":"stderr","text":"Training epoch [8/10]: 100%|██████████| 71/71 [00:27<00:00,  2.58it/s, loss=0.174] \nValidation epoch [8/10]: 100%|██████████| 8/8 [00:00<00:00,  9.09it/s]\n","output_type":"stream"},{"name":"stdout","text":"Spearman CorrCoef: 0.8209677338600159\n","output_type":"stream"},{"name":"stderr","text":"Training epoch [9/10]: 100%|██████████| 71/71 [00:27<00:00,  2.60it/s, loss=0.081] \nValidation epoch [9/10]: 100%|██████████| 8/8 [00:00<00:00,  9.37it/s]\n","output_type":"stream"},{"name":"stdout","text":"Spearman CorrCoef: 0.8371643424034119\n","output_type":"stream"},{"name":"stderr","text":"Training epoch [10/10]: 100%|██████████| 71/71 [00:27<00:00,  2.59it/s, loss=0.0814]\nValidation epoch [10/10]: 100%|██████████| 8/8 [00:00<00:00,  9.17it/s]\n","output_type":"stream"},{"name":"stdout","text":"Spearman CorrCoef: 0.8313769698143005\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"# Test the model on the test set\npbar = tqdm(dl_test)\nfor inputs in pbar:\n    # Evaluate your model\n    outputs_reg = None\n    with torch.no_grad():\n        outputs_reg = model(**inputs)\n    # Output all the evaluation scores (SpearmanCorrCoef, Accuracy, F1Score)\n    pred_reg = outputs_reg\n    spc.update(pred_reg, inputs['labels_reg'])\n\n# Print the evaluation scores\nprint(f'Spearman CorrCoef: {spc.compute()}')\n# Reset the evaluation metrics\nspc.reset()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-26T06:35:43.775007Z","iopub.execute_input":"2024-11-26T06:35:43.775716Z","iopub.status.idle":"2024-11-26T06:35:51.521856Z","shell.execute_reply.started":"2024-11-26T06:35:43.775679Z","shell.execute_reply":"2024-11-26T06:35:51.520969Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 77/77 [00:07<00:00, 10.07it/s]","output_type":"stream"},{"name":"stdout","text":"Spearman CorrCoef: 0.8125749230384827\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":16},{"cell_type":"markdown","source":"## ClsModel","metadata":{}},{"cell_type":"code","source":"# TODO2: Construct your model\nclass MultiLabelModel(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        # Write your code here\n        # Define what modules you will use in the model\n        self.bert = T.BertModel.from_pretrained(\"google-bert/bert-base-uncased\", cache_dir=\"./cache/\")\n        self.classification_head = torch.nn.Sequential(\n            torch.nn.Linear(768, 384),\n            torch.nn.ReLU(),\n            torch.nn.Linear(384, 192),\n            torch.nn.ReLU(),\n            torch.nn.Linear(192, 3)\n        )\n        \n    def forward(self, **inputs):\n        # Write your code here\n        # Forward pass\n        # BERT\n        bert_output = self.bert(inputs['input_ids'], inputs['attention_mask'], inputs['token_type_ids'])\n        # [CLS] token hidden state\n        cls_token_output = bert_output.last_hidden_state[:, 0, :]\n        # Task-specific heads\n        cls_output = self.classification_head(cls_token_output)\n\n        return cls_output","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-26T06:35:56.479290Z","iopub.execute_input":"2024-11-26T06:35:56.479936Z","iopub.status.idle":"2024-11-26T06:35:56.485849Z","shell.execute_reply.started":"2024-11-26T06:35:56.479899Z","shell.execute_reply":"2024-11-26T06:35:56.484767Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"model = ClsModel()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-26T06:36:36.032361Z","iopub.execute_input":"2024-11-26T06:36:36.032699Z","iopub.status.idle":"2024-11-26T06:36:42.543236Z","shell.execute_reply.started":"2024-11-26T06:36:36.032670Z","shell.execute_reply":"2024-11-26T06:36:42.542509Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.34G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"de06ca828ecd457a998840b96c1a0343"}},"metadata":{}}],"execution_count":19},{"cell_type":"code","source":"# TODO3: Define your optimizer and loss function\n\n# TODO3-1: Define your Optimizer\n# optimizer = torch.optim.AdamW(model.parameters(), lr=lr)# Write your code here\noptimizer = torch.optim.AdamW([\n    {'params': model.bert.parameters(), 'lr': 3e-5},\n    {'params': model.classification_head.parameters(), 'lr': 3e-3}\n])\n\n# TODO3-2: Define your loss functions (you should have two)\n# Write your code here\ncriterion_cls = torch.nn.CrossEntropyLoss()  # Classification loss\n\n# scoring functions\nacc = Accuracy(task=\"multiclass\", num_classes=3).to(device)\nf1 = F1Score(task=\"multiclass\", num_classes=3, average='macro').to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-26T06:36:43.340825Z","iopub.execute_input":"2024-11-26T06:36:43.341636Z","iopub.status.idle":"2024-11-26T06:36:43.355152Z","shell.execute_reply.started":"2024-11-26T06:36:43.341598Z","shell.execute_reply":"2024-11-26T06:36:43.354212Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"# This is the sample code from Pytorch\nif torch.cuda.device_count() > 1:\n    print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n    model = torch.nn.DataParallel(model)\n    \nmodel = model.to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-26T06:36:48.504483Z","iopub.execute_input":"2024-11-26T06:36:48.504808Z","iopub.status.idle":"2024-11-26T06:36:48.957264Z","shell.execute_reply.started":"2024-11-26T06:36:48.504774Z","shell.execute_reply":"2024-11-26T06:36:48.956551Z"}},"outputs":[{"name":"stdout","text":"Let's use 2 GPUs!\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"for ep in range(epochs):\n    pbar = tqdm(dl_train)\n    pbar.set_description(f\"Training epoch [{ep+1}/{epochs}]\")\n    model.train()\n    # TODO4: Write the training loop\n    # Write your code here\n    for inputs in pbar:\n        # train your model\n        # clear gradient\n        optimizer.zero_grad()\n        # forward pass\n        outputs_cls = model(**inputs)\n        # compute loss\n        loss_cls = criterion_cls(outputs_cls, inputs['labels_cls'])\n        # back-propagation\n        loss = loss_cls\n        loss.backward()\n        # model optimization\n        optimizer.step()\n        # update progress bar\n        pbar.set_postfix(loss=loss.item())\n\n    pbar = tqdm(dl_validation)\n    pbar.set_description(f\"Validation epoch [{ep+1}/{epochs}]\")\n    model.eval()\n    # TODO5: Write the evaluation loop\n    # Write your code here\n    for inputs in pbar:\n        # Evaluate your model\n        outputs_cls = None\n        with torch.no_grad():\n            outputs_cls = model(**inputs)\n        # Output all the evaluation scores (SpearmanCorrCoef, Accuracy, F1Score)\n        pred_cls = outputs_cls.argmax(dim=1)\n        acc.update(pred_cls, inputs['labels_cls'])\n        f1.update(pred_cls, inputs['labels_cls'])\n\n    # Print the evaluation scores\n    print(f'Accuracy: {acc.compute()}')\n    print(f'F1 Score: {f1.compute()}')\n    # Reset the evaluation metrics\n    acc.reset()\n    f1.reset()\n    # Save the model\n    torch.save(model, f'./saved_models/ep{ep}.ckpt')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-26T06:36:49.940468Z","iopub.execute_input":"2024-11-26T06:36:49.941185Z","iopub.status.idle":"2024-11-26T06:51:26.074814Z","shell.execute_reply.started":"2024-11-26T06:36:49.941151Z","shell.execute_reply":"2024-11-26T06:51:26.073813Z"}},"outputs":[{"name":"stderr","text":"Training epoch [1/10]: 100%|██████████| 71/71 [01:24<00:00,  1.19s/it, loss=0.683]\nValidation epoch [1/10]: 100%|██████████| 8/8 [00:03<00:00,  2.16it/s]\n","output_type":"stream"},{"name":"stdout","text":"Accuracy: 0.7820000052452087\nF1 Score: 0.7963052988052368\n","output_type":"stream"},{"name":"stderr","text":"Training epoch [2/10]: 100%|██████████| 71/71 [01:21<00:00,  1.15s/it, loss=0.39] \nValidation epoch [2/10]: 100%|██████████| 8/8 [00:03<00:00,  2.30it/s]\n","output_type":"stream"},{"name":"stdout","text":"Accuracy: 0.8479999899864197\nF1 Score: 0.8446929454803467\n","output_type":"stream"},{"name":"stderr","text":"Training epoch [3/10]: 100%|██████████| 71/71 [01:20<00:00,  1.14s/it, loss=0.205]\nValidation epoch [3/10]: 100%|██████████| 8/8 [00:03<00:00,  2.32it/s]\n","output_type":"stream"},{"name":"stdout","text":"Accuracy: 0.8659999966621399\nF1 Score: 0.8610131740570068\n","output_type":"stream"},{"name":"stderr","text":"Training epoch [4/10]: 100%|██████████| 71/71 [01:20<00:00,  1.13s/it, loss=0.192] \nValidation epoch [4/10]: 100%|██████████| 8/8 [00:03<00:00,  2.27it/s]\n","output_type":"stream"},{"name":"stdout","text":"Accuracy: 0.8320000171661377\nF1 Score: 0.821036696434021\n","output_type":"stream"},{"name":"stderr","text":"Training epoch [5/10]: 100%|██████████| 71/71 [01:21<00:00,  1.14s/it, loss=0.159]\nValidation epoch [5/10]: 100%|██████████| 8/8 [00:03<00:00,  2.32it/s]\n","output_type":"stream"},{"name":"stdout","text":"Accuracy: 0.878000020980835\nF1 Score: 0.8655569553375244\n","output_type":"stream"},{"name":"stderr","text":"Training epoch [6/10]: 100%|██████████| 71/71 [01:20<00:00,  1.14s/it, loss=0.0378]\nValidation epoch [6/10]: 100%|██████████| 8/8 [00:03<00:00,  2.31it/s]\n","output_type":"stream"},{"name":"stdout","text":"Accuracy: 0.8640000224113464\nF1 Score: 0.8606765270233154\n","output_type":"stream"},{"name":"stderr","text":"Training epoch [7/10]: 100%|██████████| 71/71 [01:20<00:00,  1.14s/it, loss=0.154]  \nValidation epoch [7/10]: 100%|██████████| 8/8 [00:03<00:00,  2.26it/s]\n","output_type":"stream"},{"name":"stdout","text":"Accuracy: 0.8600000143051147\nF1 Score: 0.8503251075744629\n","output_type":"stream"},{"name":"stderr","text":"Training epoch [8/10]: 100%|██████████| 71/71 [01:20<00:00,  1.13s/it, loss=0.0722] \nValidation epoch [8/10]: 100%|██████████| 8/8 [00:03<00:00,  2.31it/s]\n","output_type":"stream"},{"name":"stdout","text":"Accuracy: 0.8560000061988831\nF1 Score: 0.846443772315979\n","output_type":"stream"},{"name":"stderr","text":"Training epoch [9/10]: 100%|██████████| 71/71 [01:21<00:00,  1.14s/it, loss=0.0824] \nValidation epoch [9/10]: 100%|██████████| 8/8 [00:03<00:00,  2.30it/s]\n","output_type":"stream"},{"name":"stdout","text":"Accuracy: 0.8619999885559082\nF1 Score: 0.8548198938369751\n","output_type":"stream"},{"name":"stderr","text":"Training epoch [10/10]: 100%|██████████| 71/71 [01:20<00:00,  1.14s/it, loss=0.00441]\nValidation epoch [10/10]: 100%|██████████| 8/8 [00:03<00:00,  2.26it/s]\n","output_type":"stream"},{"name":"stdout","text":"Accuracy: 0.8539999723434448\nF1 Score: 0.846053957939148\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"# Test the model on the test set\npbar = tqdm(dl_test)\nfor inputs in pbar:\n    # Evaluate your model\n    outputs_cls = None\n    with torch.no_grad():\n        outputs_cls = model(**inputs)\n    # Output all the evaluation scores (SpearmanCorrCoef, Accuracy, F1Score)\n    pred_cls = outputs_cls.argmax(dim=1)\n    acc.update(pred_cls, inputs['labels_cls'])\n    f1.update(pred_cls, inputs['labels_cls'])\n\n# Print the evaluation scores\nprint(f'Accuracy: {acc.compute()}')\nprint(f'F1 Score: {f1.compute()}')\n\n# Reset the evaluation metrics\nacc.reset()\nf1.reset()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-26T06:51:26.620852Z","iopub.execute_input":"2024-11-26T06:51:26.621667Z","iopub.status.idle":"2024-11-26T06:51:57.013481Z","shell.execute_reply.started":"2024-11-26T06:51:26.621632Z","shell.execute_reply":"2024-11-26T06:51:57.012499Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 77/77 [00:30<00:00,  2.53it/s]","output_type":"stream"},{"name":"stdout","text":"Accuracy: 0.8591434955596924\nF1 Score: 0.8502813577651978\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}